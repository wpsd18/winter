---
title: "Rendu Travaux Pratiques 3"
output:
  html_document: default
  html_notebook: default
---

** **

#### Règles de rendu

* Chaque TP donne lieu à un bref compte-rendu portant sur certaines questions posées dans l'énoncé du TPs.

* Le compte-rendu doit être complété à partir du texte de l'énoncé. Les codes R doivent être inclus dans le texte du compte-rendu (menu **Insert**) et commentés avec précision. **Les commentaires compteront pour une part importante dans la note**.

* Le compte-rendu doit être déposé **sur TEIDE à la fin de la séance de TP**. Les rendus en retard seront fortement pénalisés. 

* Le compte-rendu doit être déposé **sur TEIDE au format HTML uniquement**. Utiliser la fonction **Preview** ou **knitr** du menu de rstudio pour obtenir le document au format souhaité. **Les fichiers "source" (Rmd) ne seront pas acceptés par les correcteurs**.


** **

```{r}
library(isd)
library(magrittr)
```



#### Exercice 1 :  Données simulées (knn)

Dans cet exercice, on fixera la graine du générateur aléatoire pour la simulation du modèle de Hastie. 

```{r}
set.seed(seed = 2149)
```


* Méthode `knn` : Pour $k = 1,\dots, 30$, calculer l'erreur de classification et la perte log loss à partir de l'ensemble test (on modifiera les probabilités 0 ou 1  pour éviter les valeurs "Inf"). Représenter ces résultats sous la forme de graphes "accuracy" et "logloss" en fonction de $k$.

*  Quel choix de $k$ vous parait le plus pertinent pour la simulation effectuée ?


#### Exercice 2 : Données simulées (lda)

* Méthode `lda` : Calculer le taux de bonne classification et la perte log loss sur l'ensemble test. 


#### Exercice 3 : Données simulées (nnet) 

* Méthode `nnet` :  Pour `decay` = 0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, calculer le taux de bonne classification et la perte log loss sur l'ensemble test. Représenter ces résultats sous forme de tableau (accuracy/logloss en fonction du paramètre `decay`). Quel choix vous parait le plus pertinent pour la simulation effectuée ?


#### Exercice 4 : "Wisconsin Breast Cancer Database" 

Dans cet exercice, on fixera la graine du générateur aléatoire pour la création d'ensembles d'apprentissage et de test. 

```{r}
set.seed(seed = 5341)
```


* À l'aide de l'ensemble test, évaluer les taux de classification et de perte log loss pour les méthodes `lda`, `nnet` et `knn`. Pour `knn` et `nnet`, utiliser, dans un premier temps, les paramètres $k = 15$ et `decay` = 0.01.

* Reporter sous forme de tableau avec des valeurs arrondies les valeurs des taux de classification et de perte log loss obtenues pour les méthodes `knn`, `lda`, `nnet` (dans cet ordre).  Quel choix de prédicteur vous parait être le meilleur ? Justifier.

* Pour `knn` et `nnet`, explorer les paramètres de "complexité" ($k$ et `decay`) conduisant aux meilleures performances. Reporter les performances des modèles correspondant à l'aide d'une courbe pour `knn` et dans un tableau pour `nnet`. Quels choix vous paraissent les plus pertinents pour la simulation effectuée ?

#### Défi "Wisconsin Breast Cancer Database" 

```{r}
rm(cancer_test)
rm(cancer_train)
data(cancer_train)
data(cancer_test)
```


* Pour les méthodes `knn`, `lda`, `nnet`, calculer les probabilités de la classe "malignant" pour chaque élément de l'ensemble test. On choisira les paramètres `k` et `decay` donnant les meilleures performances lors de la question précédente.

* Pour les méthodes `knn`, `lda`, `nnet`, appliquer  la fonction `eval_cancer` et présenter les résultats sous forme de tableau (`data.frame`). Quelle méthode obtient les meilleures performances ?

