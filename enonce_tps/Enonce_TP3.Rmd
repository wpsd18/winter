---
title: "Séance de travaux pratiques 3"
output:
  html_document: default
  html_notebook: default
---

** **

#### [Introduction à R](https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf) 

* Livre en français de [Vincent Goulet](https://cran.r-project.org/doc/contrib/Goulet_introduction_programmation_R.pdf)

* R pour les débutants [Emmanuel Paradis](https://cran.r-project.org/doc/contrib/Paradis-rdebuts_fr.pdf)


* Liste des [fonctions de base](https://stat.ethz.ch/R-manual/R-devel/library/base/html/00Index.html).


** **

**IMPORTANT** : Cet énoncé est un document de travail intéractif personnel **qui ne doit pas être rendu**. Le **compte-rendu de TP est un document séparé** et seul **le compte-rendu doit être déposé dans TEIDE en fin de séance** au format HTML. 

Il est fortement conseillé **de préparer le TP** pour le réussir et pour **déposer le compte-rendu** dans de bonnes conditions. La préparation consiste à lire l'intégralité du TP, à en comprendre les principales étapes et celles nécessitant des recherches dans l'aide du programme. La préparation consiste aussi à lire le fichier de compte-rendu pour **identifier les réponses à rendre dans l'énoncé**.

Le **rendu porte notamment sur les questions finales**. Il faut gérer son temps le mieux possible. La préparation et l'organisation pendant le TP sont essentielles. 


** **

L'objectif de cette séance de travaux pratiques est de comparer les performances de trois méthodes de classification supervisée : les méthodes des $k$-plus proches voisins, de l'analyse discriminante linéaire et un réseaux de neurones à une couche cachée. Il s'agit de bien comprendre le phénomène de sur-entrainement (overfitting) et de choisir les paramètres des classifieurs permettant de minimiser son effet.

Dans la première partie du TP, on utilisera des données simulées comportant 2 classes, de distribution conditionnelle non gaussienne. Cette simulation est inspirée de l'ouvrage de référence de Hastie, Tibshirani et Friedman intitulé [the Elements of Statistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) (les meilleurs ouvrages de référence sont écrits en anglais).

Dans la seconde partie du TP, on utilisera des données réelles comportant 2 classes, issues de la base de données de cancers du sein du Wisconsin ([Wisconsin Breast Cancer Database](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original))). Il s'agit d'un tableau de données comportant 699 échantillons et 11 variables, la première étant un identifiant individuel, les neuf suivantes étant des descripteurs de la tumeur et la dernière indiquant le diagnostic de cancer.




On prendra soin de commenter les codes R tout au long des questions du TP. Il est demandé de compléter certains codes en utilisant l'aide en ligne du programme avec la commande `help()`. 

**Tous les codes rendus devront être complets et commentés et les commentaires compteront pour une par importante dans la note**.







```{r}
#install.packages("devtools")
#devtools::install_github("bcm-uga/isd")
library(isd)
```


#### Exercice 1: 45 minutes

Le modèle de simulation de Hastie et Tibshirani (`rhastib`) consiste à simuler *n.train + n.test* données réparties en deux classes appelées "bleue" et "orange" selon un feu d'artifice gaussien en deux dimensions. 

La classe "bleue" est centrée en $(1,0)$ et `n.subclass` sous-classes sont générées selon la loi gaussienne de moyenne $(0,1)$ et de covariance identité ${\bf Id}$. Les données sont simulées en choisissant une sous-classe $m_k$ au hasard parmi les `n.subclass` sous-classes selon une loi de variance `sigma2` plus petite que 1, $N(m_k, \sigma^2 {\bf I})$. 

La classe "orange" obéit au même principe de génération à partir de la valeur moyenne $(1,0)$ plutôt que la valeur $(0,1)$ correspondant à la classe "bleue". Les deux classes sont supposées équilibrées.

La fonction `rhastib()` prend en arguments les variables `n_train`, `n_test` représentant les nombres d'échantillons des données d'apprentissage et de test,  `n_subclass` représentant la complexité des classes (nombre de sous-classes) et `sigma2` représentant la dispersion des observations à l'intérieur des sous-classes.

```{r}
help(rhastib)
```

* Le code suivant simule 200 données d'apprentissage, 200 données de tests en utilisant 10 sous-classes. La variance des sous-classes est fixée à 0.05. Commenter le code et visualiser les données colorées selon leur classe. 

```{r}
#
  x <- isd::rhastib(n_train = 200,
                    n_test = 200,
                    n_subclass = 10,
                    sigma2 = 0.05)

#
  plot(x$train, pch = 19, col = x$class_train)
  plot(x$test, pch = 19, col = x$class_test)
```


* A partir de l'ensemble d'apprentissage, utiliser la fonction `knn` de la bibliothèque `class` pour calculer la probabilité de classification pour **tout élément de l'ensemble test**.  Commenter et compléter le code ci-dessous. On considèrera 10 voisins dans l'algorithme.

```{r}
library(class)
help(knn)

#
  mod_knn <- knn( train = what_the_f, 
                  test = x$test, 
                  cl = change_me, 
                  k = change_moi, 
                  prob = TRUE)

# 
  class_pred <- mod_knn
  prob_class <- attr(mod_knn, "prob")
  
# attention : les  probabilités correspondent aux classes prédites 
```


* Pour $k = 1O$, calculer le taux de bonne classification et la perte logloss à partir de l'ensemble test.

```{r}
# Nombre moyen de bons classements 
  accuracy <- mean(class_pred == truck_mich)
  accuracy

# log_loss = - mean(y*log(pred) + (1-y)*log(1-pred))
# Les probabilités sont modifiées pour éviter Inf  
  prob_class[prob_class == 1] <- 1 - 1e-09
  prob_class[prob_class == 0] <- 1e-09 
  
# attention : les  probabilités correspondent aux classes prédites 
# attention : il faut tenir compte de la classe des variables testées
  log_loss <- pas_si_simple
  log_loss
```



* Pour $k = 1,\dots, 30$, calculer le taux de bonne classification et la perte logloss à partir de l'ensemble test (on modifiera les probabilités pour éviter Inf). Représenter ces résultats sous la forme de graphes accuracy et logloss en fonction de $k$.


```{r}
accuracy <- NULL
log_loss <-  NULL

for (k in 1:30){
  
  #
  mod_knn <- class::knn(train = what_the_f, 
                        test = x$test, 
                        cl = change_me, 
                        k = k, 
                        prob = TRUE)
  
  #
  class_pred <- mod_knn
  prob_class <- attr(mod_knn,"prob")
  
  # les probabilités sont modifiées pour éviter Inf  
  prob_class[prob_class == 1] <- 1 - 1e-09 
  prob_class[prob_class == 0] <- 1e-09 

  #
  accuracy[k] <- mean(class_pred == truck_mich)
  
  boo <- (class_pred == x$class_test)
  log_loss[k] <- - mean(log(prob_class[boo])) - mean(log(1 - prob_class[!boo]))
}

par(mfrow = c(1, 2)) # divise la fenetre en 1 ligne 2 colonnes
plot(accuracy, col = "lightblue", type = "l", lwd = 3, xlab = "Nombre de voisins")
plot(log_loss, col = "palegreen", type = "l", lwd = 3, xlab = "Nombre de voisins")
```


*  Quel choix de $k$ vous parait le plus pertinent pour obtenir les meilleures prédictions sur l'ensemble test ?


#### Exercice 2 (Analyse discriminante linéaire) : 30 minutes

On poursuit l'analyse du jeu de données simulées en faisant l'hypothèse (erronée) que les lois des variables à l'intérieur des classes "bleue" et "orange" sont gaussiennes et de même matrice de covariance. Nous avons étudié ou allons étudier cette méthode de classification en travaux dirigés. Elle est connue sous le nom *analyse discriminante linéaire* (*linear discriminant analysis*, *lda* en anglais).

* Utiliser la fonction `lda` de la bibliothèque `MASS` pour calculer une probabilité de classification pour **tout élément de l'ensemble test**.  Commenter et compléter le code ci-dessous. 


```{r}
require(MASS)
help(lda)

#
    mod_lda <- MASS::lda(x = what_is_it, 
                         grouping = was_is_das)

help(predict.lda)

#   
    pred <- predict(mod_lda, newdata = nom_du_test_set)
    
# Les  probabilités correspondent aux classes des variables testées     
    prob_class <- pred$posterior

#
    barplot(t(prob_class), col = c("lightblue", "orange"),
            border = NA,
            xlab = "Test set")
    head(prob_class)
```



* Calculer le taux de bonne classification et la perte log loss sur l'ensemble test. Commenter et compléter le code suivant.


```{r}
#
  accuracy <- mean(what_the_f == pred$class)
  cat("Accuracy = ", accuracy, "\n")
  
# 
  log_loss <- -mean( (x$class_test == "lightblue")*log(change_me) + (x$class_test == "orange")*log(change_moi) )
  cat("Logloss = ", log_loss, "\n")

```





#### Exercice 3 (Réseaux de neurones) : 30 minutes

On essaie maintenant de prédire la classe  des données de test à l'aide de réseaux de neurones ayant une couche de neurones cachés. Comme précédemment, l'apprentissage se fait à partir des données `x$train` et `x$class_train`. Nous supposons que les réseaux de neurones sont entrainés pour minimiser la perte log loss (entropie).


* Utiliser la fonction `nnet` de la bibliothèque `nnet` pour calculer une probabilité de classification pour chaque élément de l'ensemble test. On supposera tout d'abord que le réseau de neurones possède 30 neurones cachés. On fixera le paramètre de régularisation (`decay`) à 0.01. Commenter et compléter le code suivant.


```{r}
require(nnet)
help(nnet)

#
  is_it_orange <- (x$class_train == "orange")
  mod_nnet <- nnet( x = change_me, 
                    y = is_it_orange, 
                    size = change_moi,
                    decay = 0.01,
                    entropy = TRUE,
                    trace = FALSE)

#
help(predict.nnet)

#  
prob_class <- predict(ques_a_quo, newdata = data.frame(x$test))
head(proba_class)
```




* Calculer le taux de bonne classification et la perte log loss sur l'ensemble test. On exécutera éventuellement le chunck de code précédent plusieurs fois.

```{r}
# 
  accuracy <- mean(logical_to_test == (prob_class > 0.5))
  accuracy

#  
  log_loss <- - mean((x$class_test == "lightblue")*log(1 - prob_class)) - complete_la_formule
  log_loss
```



* Pour `decay`$ = 0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1$, calculer le taux de bonne classification et la perte log loss sur l'ensemble test. Représenter ces résultats sous forme de tableau (accuracy/logloss en fonction de `decay`). Commenter et completer le code suivant.


```{r}
accuracy <- NULL
log_loss <-  NULL

  decay <- c(0, 10^(-(6:0)))

# On ajuste des modeles nnet pour 7 valeurs du paramètre decay
# decay est un paramètre de régularisation  
  
  for (lambda in decay){
    
    # neural net 
    mod_nnet <- nnet( x = change_me, 
                      y = is_it_orange, 
                      size = 30,
                      decay = lambda,
                      maxit = 500,
                      entropy = TRUE,
                      trace = FALSE)
    
    # probabilité de prédiction en orange
    prob_class <- predict(comme_le_temps_passe, newdata = data.frame(x$test))
  
    prob_class[prob_class > 1 - 1e-08]  <- 1 - 1e-08
    prob_class[prob_class < 1e-08] <- 1e-08
  
    # 
    accuracy <- c(accuracy, 
                  mean((x$class_test == "orange") == el_truc_rigolo))
  
    # calul de la perte log loss
    log_loss <- c( log_loss, 
                - mean((x$class_test == "lightblue")*log(1 - prob_class)) - mean((x$class_test == "orange")*log(cambia_mi)) ) 
}
```

```{r}
# help(kable) pour faire une table
# il n'y a rien à changer
library(magrittr)

  names(accuracy) <- as.character(decay)
  names(log_loss) <- as.character(decay)
  
  data.frame(accuracy, log_loss)  %>% knitr::kable(digit = 2)
```



#### Exercice 4 :  "Wisconsin Breast Cancer Database" : 1H15 incluant le rendu


Wisconsin Breast Cancer Database" est un tableau de données contenant neuf caracteristiques mesurées sur les tumeurs cancéreuses de 699 patientes (Données du Dr William H. Wolberg, University of Wisconsin Hospital, Madison, Wisconsin USA). Toutes les variables ont été converties en valeurs numériques variant entre 0 et 10 (Il y a 16 données manquantes). Voici les noms des variables et leur signification.

-	Id	Sample code number
-	Cl.thickness	Clump Thickness
-	Cell.size	Uniformity of Cell Size
-	Cell.shape	Uniformity of Cell Shape
-	Marg.adhesion	Marginal Adhesion
-	Epith.c.size	Single Epithelial Cell Size
-	Bare.nuclei	Bare Nuclei
-	Bl.cromatin	Bland Chromatin
-	Normal.nucleoli	Normal Nucleoli
-	Mitoses	Mitoses
-	Class	Class

La dernière colonne contient la classification des tumeurs en deux classes ("benign" et "malignant"). 

```{r}
library(mlbench)
data(BreastCancer)
head(BreastCancer)
```

* \'Eliminer les lignes contenant des données manquantes (cf TD). C'est donné.

```{r}
  boo_na <- !apply(BreastCancer, 1, anyNA)
  breast_cancer <- BreastCancer[boo_na,-1]
  dim(breast_cancer)
```


* Constituer un ensemble d'apprentissage contenant 546 profils de tumeurs et un ensemble test, disjoint du premier ensemble, contenant 137 profils de tumeurs. Les ensembles seront constitués par tirage dans une urne contenant tous les profils.


```{r}
# sample : 
  cancer_samp <- sample(1:nrow(breast_cancer), 546)

#
  cancer_train <- breast_cancer[quelque_chose_de_tennessee,]
  cancer_test <- breast_cancer[-quelque_chose_de_tennessee,]
```



* À l'aide de l'ensemble test, évaluer les taux de classification et de perte log loss pour les méthodes `lda`, `nnet` et `knn`. Pour `knn` et `nnet`, utiliser, dans un premier temps, les paramètres $k = 15$ et `decay`$=0.01$.


Pour l'analyse discriminante, compléter et commenter le code suivant.

```{r}

    # lda
      mod_lda <- MASS::lda(change_me  ~ ., data = cancer_train[,-10])

      pred_lda <- predict(mod_lda, newdata = cancer_test[,-10])$class
      
      accuracy_lda <- mean(change_moi == cancer_test$Class)
      
      prob_lda <- predict(whaaat_again, newdata = cancer_test[,-10])$posterior
      
      log_loss_lda <- -mean((cancer_test$Class == "benign")*log(ron_tud_ju) + (cancer_test$Class == "malignant")*log(m_enfin)) 
      
      accuracy_lda
      log_loss_lda
```

Pour un réseau de neurones, compléter et commenter le code suivant.

```{r}
    # nnet
      y <-  as.numeric(cancer_train$Class == "malignant")
      
      mod_nnet <- nnet::nnet(x = cancer_train[,-10], 
                             y = change_me, 
                             size = 30,
                             entropy = TRUE, 
                             decay = 0.01, 
                             trace = FALSE)
      
      prob_nnet <- predict(mod_nnet, change_moi[,-10])
      prob_nnet[prob_nnet == 0] <- 1e-08
      prob_nnet[prob_nnet == 1] <- 1 - 1e-08
      
      accuracy_nnet <- mean(c_est_pas_faux == (cancer_test$Class == "malignant"))

      log_loss_nnet <- -mean((cancer_test$Class == "benign")*log(1 - prob_nnet) + (cancer_test$Class == "malignant")*log(pas_changer_assiette)) 
      
      accuracy_nnet
      log_loss_nnet
```


Pour la méthode des $k$ plus proches voisins, compléter et commenter le code suivant.

```{r}
    # knn
     mod_knn <- class::knn(cancer_train[,-10], 
                            cancer_test[,-10], 
                            change_me$Class, 
                            k = 15, 
                            prob = TRUE)

      accuracy_knn <- mean(mod_knn == cancer_test$change_moi)
      prob_class <- attr(mod_knn, "prob")
      prob_class[prob_class == 1] <-  1 - 1e-08
      
      log_loss_knn <- - mean( (mod_knn == cancer_test$Class)*log(c_est_pas_faux) + (mod_knn != cancer_test$Class)*log(pas_changer_assiette) )
``` 




* Reporter dans des diagrammes en barres les valeurs des taux de classification et de perte log loss obtenues pour les méthodes `knn`, `lda`, `nnet` (dans cet ordre).  Quel choix de prédicteur vous parait être le meilleur ? Justifier.


```{r}
  log_loss <-  c(il_faut_3_valeurs_séparées_par_des_virgules)

  names(log_loss) <-  c("knn", "lda", "nnet")
  
  barplot(log_loss, col = 2:4, ylab = "log loss")
  
  accuracy <- be_inspired
  
  names(accuracy) <-  c("knn", "lda", "nnet")
  
  barplot(accuracy, col = 2:4, ylab = "accuracy") 
```

* Puis sous forme de tableau avec des valeurs arrondies

```{r}
library(magrittr)
data.frame(log_loss, accuracy) %>% round(2)
```



* Pour `knn` et `nnet`, explorer les paramètres de "complexité" ($k$ et `decay`) conduisant aux meilleures performances. Reporter les performances des modèles correspondant dans un tableau.


#### Défi "Wisconsin Breast Cancer Database" : Evaluation finale

* Charger en mémoire les jeux de données `cancer_train` et `cancer_test` de la bibliothèque `isd`. Le jeu d'apprentissage contient 413 profils de tumeurs, et la variable `Class` est enregistrée dans la dixième colonne du tableau. La classification n'est pas donnée pour le jeu de données test, qui contient 150 profils de tumeurs.

```{r}
data(cancer_train)
data(cancer_test)
```

* Pour les méthodes `knn`, `lda`, `nnet`, calculer les probabilités de la classe "malignant" pour chaque élément de la l'ensemble test. On choisira les paramètres `k` et `decay` donnant les meilleures performances possibles.

```{r}
# entrainement d'un modèle à paramétrer
mod_mymethod <-  my_method(cancer_train[,-10], cancer_train$Class)

# proba de la classe "malignant" pour l'ensemble test 
prob <- predict(mod_mymethod, cancer_test) 

```

* Pour les méthodes `knn`, `lda`, `nnet`, appliquer  la fonction `eval_cancer` et présenter les résultat sous forme de tableau (`data.frame`).

```{r}
# accuracy et log loss sur l'ensemble test
# help(eval_cancer)
eval_cancer(prob) 
```


